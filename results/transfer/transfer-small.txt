You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with lora is: f1 0.9629629629629629, acc 0.981651376146789
The preditive performance trained on iTunes-Amazon and test on Beer with lora is: f1 0.42424242424242425, acc 0.5824175824175825
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with lora is: f1 0.9545454545454546, acc 0.9894179894179894
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with lora is: f1 0.19057171514543633, acc 0.212298682284041
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with lora is: f1 0.23233908948194665, acc 0.36022677714784124
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with lora is: f1 0.42250834525512637, acc 0.5103113627173473
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with lora is: f1 0.4885714285714285, acc 0.625914315569488
The preditive performance trained on iTunes-Amazon and test on Hospital with lora is: f1 0.051002387465458314, acc 0.10806385591485879
The preditive performance trained on iTunes-Amazon and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with lora is: f1 0.6222222222222222, acc 0.8440366972477065
The preditive performance trained on Beer and test on Beer with lora is: f1 0.9333333333333333, acc 0.978021978021978
The preditive performance trained on Beer and test on Fodors-Zagats with lora is: f1 0.761904761904762, acc 0.9470899470899471
The preditive performance trained on Beer and test on Walmart-Amazon with lora is: f1 0.3283008754690013, acc 0.838457784285017
The preditive performance trained on Beer and test on Amazon-Google with lora is: f1 0.22277338445562747, acc 0.5769733972961186
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with lora is: f1 0.46977730646871685, acc 0.5956328346138293
The preditive performance trained on Beer and test on DBLP-GoogleScholar with lora is: f1 0.4355573974305843, acc 0.5256008359456635
The preditive performance trained on Beer and test on Hospital with lora is: f1 0.05150116789152851, acc 0.02643120285363429
The preditive performance trained on Beer and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with lora is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Fodors-Zagats and test on Beer with lora is: f1 0.0, acc 0.8351648351648352
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with lora is: f1 0.9767441860465117, acc 0.9947089947089947
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with lora is: f1 0.0, acc 0.8970229380185456
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with lora is: f1 0.016949152542372885, acc 0.8988225032708242
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with lora is: f1 0.07357357357357358, acc 0.8265264860493328
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with lora is: f1 0.036621668397369335, acc 0.8169627307558343
The preditive performance trained on Fodors-Zagats and test on Hospital with lora is: f1 2.9394862659852937e-06, acc 0.19338050406408983
The preditive performance trained on Fodors-Zagats and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with lora is: f1 0.7272727272727274, acc 0.8348623853211009
The preditive performance trained on Walmart-Amazon and test on Beer with lora is: f1 0.6086956521739131, acc 0.8021978021978022
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with lora is: f1 0.9302325581395349, acc 0.9841269841269841
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with lora is: f1 0.7918781725888324, acc 0.9599804782820889
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with lora is: f1 0.4256352113494971, acc 0.8752725686873092
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with lora is: f1 0.861111111111111, acc 0.9433885968459361
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with lora is: f1 0.7982261640798227, acc 0.9207593173110414
The preditive performance trained on Walmart-Amazon and test on Hospital with lora is: f1 0.007663752461753054, acc 0.27191392316238816
The preditive performance trained on Walmart-Amazon and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with lora is: f1 0.5833333333333334, acc 0.7247706422018348
The preditive performance trained on Amazon-Google and test on Beer with lora is: f1 0.4905660377358491, acc 0.7032967032967034
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with lora is: f1 0.48, acc 0.7936507936507936
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with lora is: f1 0.23058404325494594, acc 0.5968765251342119
The preditive performance trained on Amazon-Google and test on Amazon-Google with lora is: f1 0.7246376811594204, acc 0.9419973833406018
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with lora is: f1 0.825, acc 0.9264051758997169
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with lora is: f1 0.8008547008547008, acc 0.9188436084987809
The preditive performance trained on Amazon-Google and test on Hospital with lora is: f1 0.008676789587852495, acc 0.9732764165838255
The preditive performance trained on Amazon-Google and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with lora is: f1 0.6440677966101694, acc 0.8073394495412844
The preditive performance trained on DBLP-ACM and test on Beer with lora is: f1 0.49122807017543857, acc 0.6813186813186813
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with lora is: f1 0.8260869565217391, acc 0.9576719576719577
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with lora is: f1 0.243811168681635, acc 0.5641776476329917
The preditive performance trained on DBLP-ACM and test on Amazon-Google with lora is: f1 0.40236686390532544, acc 0.8905364151766245
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with lora is: f1 0.9875706214689265, acc 0.9955519611807522
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with lora is: f1 0.43799854967367663, acc 0.8650296064089168
The preditive performance trained on DBLP-ACM and test on Hospital with lora is: f1 0.004347826086956523, acc 0.9732179404713175
The preditive performance trained on DBLP-ACM and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with lora is: f1 0.6666666666666666, acc 0.7614678899082569
The preditive performance trained on DBLP-GoogleScholar and test on Beer with lora is: f1 0.375, acc 0.5604395604395604
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with lora is: f1 0.7457627118644068, acc 0.9206349206349206
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with lora is: f1 0.23008237128643905, acc 0.4992679355783309
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with lora is: f1 0.4221547458389564, acc 0.8517226341037941
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with lora is: f1 0.9646799116997793, acc 0.9870602507076426
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with lora is: f1 0.9526022304832714, acc 0.9822361546499477
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with lora is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-GoogleScholar and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with lora is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Hospital and test on Beer with lora is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Hospital and test on Fodors-Zagats with lora is: f1 0.0, acc 0.8835978835978836
The preditive performance trained on Hospital and test on Walmart-Amazon with lora is: f1 0.00872647941096264, acc 0.9004392386530015
The preditive performance trained on Hospital and test on Amazon-Google with lora is: f1 0.0, acc 0.8979502834714348
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with lora is: f1 0.004054054054054054, acc 0.8188435099069955
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with lora is: f1 0.0018691588785046728, acc 0.8131313131313131
The preditive performance trained on Hospital and test on Hospital with lora is: f1 0.9484536082474228, acc 0.9973685749371382
The preditive performance trained on Hospital and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Beer with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Amazon-Google with lora is: f1 0.0, acc 0.002180549498473615
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on DBLP-GoogleScholar with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Hospital with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Buy with lora is: f1 0.0, acc 0.9230769230769231
The preditive performance trained on Buy and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on iTunes-Amazon with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Amazon-Google with lora is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Restaurant with lora is: f1 0.0, acc 0.8953488372093024
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with p-tune is: f1 0.9019607843137256, acc 0.9541284403669725
The preditive performance trained on iTunes-Amazon and test on Beer with p-tune is: f1 0.4745762711864407, acc 0.6593406593406593
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with p-tune is: f1 0.5806451612903226, acc 0.9312169312169312
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with p-tune is: f1 0.2836185819070905, acc 0.5710102489019033
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with p-tune is: f1 0.30684699915469144, acc 0.8652420409943306
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with p-tune is: f1 0.8071519795657726, acc 0.9389405580266882
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with p-tune is: f1 0.6674107142857144, acc 0.8962034134447927
The preditive performance trained on iTunes-Amazon and test on Hospital with p-tune is: f1 0.017994168556486327, acc 0.6204900298228174
The preditive performance trained on iTunes-Amazon and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with p-tune is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Beer and test on Beer with p-tune is: f1 0.7857142857142857, acc 0.9340659340659341
The preditive performance trained on Beer and test on Fodors-Zagats with p-tune is: f1 0.44545454545454544, acc 0.8201058201058201
The preditive performance trained on Beer and test on Walmart-Amazon with p-tune is: f1 0.20192367717182003, acc 0.5207418252806247
The preditive performance trained on Beer and test on Amazon-Google with p-tune is: f1 0.2812720848056537, acc 0.5564762320104666
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with p-tune is: f1 0.6005747126436782, acc 0.7751718560452892
The preditive performance trained on Beer and test on DBLP-GoogleScholar with p-tune is: f1 0.38859649122807016, acc 0.5144548937652386
The preditive performance trained on Beer and test on Hospital with p-tune is: f1 0.049911349957345766, acc 0.14659961405765745
The preditive performance trained on Beer and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with p-tune is: f1 0.75, acc 0.8899082568807339
The preditive performance trained on Fodors-Zagats and test on Beer with p-tune is: f1 0.2916666666666667, acc 0.25274725274725274
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with p-tune is: f1 0.9523809523809523, acc 0.9894179894179894
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with p-tune is: f1 0.2568039078855548, acc 0.4802342606149341
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with p-tune is: f1 0.2724741255814702, acc 0.595290013083297
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with p-tune is: f1 0.9058693244739756, acc 0.9656287909421755
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with p-tune is: f1 0.5576470588235294, acc 0.869035179380007
The preditive performance trained on Fodors-Zagats and test on Hospital with p-tune is: f1 0.05227790432801823, acc 0.026840535641190575
The preditive performance trained on Fodors-Zagats and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with p-tune is: f1 0.819672131147541, acc 0.8990825688073395
The preditive performance trained on Walmart-Amazon and test on Beer with p-tune is: f1 0.4827586206896552, acc 0.6703296703296703
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with p-tune is: f1 0.5806451612903226, acc 0.9312169312169312
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with p-tune is: f1 0.6380697050938339, acc 0.9341142020497804
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with p-tune is: f1 0.18592257415786828, acc 0.8983863933711296
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with p-tune is: f1 0.8934240362811793, acc 0.9619894864537
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with p-tune is: f1 0.5443708609271523, acc 0.8801811215604319
The preditive performance trained on Walmart-Amazon and test on Hospital with p-tune is: f1 0.04590855597678065, acc 0.024969300040933277
The preditive performance trained on Walmart-Amazon and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with p-tune is: f1 0.7719298245614035, acc 0.8807339449541285
The preditive performance trained on Amazon-Google and test on Beer with p-tune is: f1 0.7000000000000001, acc 0.8681318681318682
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with p-tune is: f1 0.717948717948718, acc 0.9417989417989417
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with p-tune is: f1 0.31933195834800543, acc 0.7388970229380185
The preditive performance trained on Amazon-Google and test on Amazon-Google with p-tune is: f1 0.6762295081967213, acc 0.9310946358482337
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with p-tune is: f1 0.8793103448275863, acc 0.9547108774767489
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with p-tune is: f1 0.8564500484966052, acc 0.9484500174155347
The preditive performance trained on Amazon-Google and test on Hospital with p-tune is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Amazon-Google and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with p-tune is: f1 0.5405405405405406, acc 0.8440366972477065
The preditive performance trained on DBLP-ACM and test on Beer with p-tune is: f1 0.65, acc 0.8461538461538461
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with p-tune is: f1 0.7777777777777778, acc 0.9576719576719577
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with p-tune is: f1 0.32718990158917827, acc 0.8550512445095169
The preditive performance trained on DBLP-ACM and test on Amazon-Google with p-tune is: f1 0.11538461538461539, acc 0.9031836022677715
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with p-tune is: f1 0.9875141884222476, acc 0.9955519611807522
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with p-tune is: f1 0.43699927166788055, acc 0.865377917102055
The preditive performance trained on DBLP-ACM and test on Hospital with p-tune is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-ACM and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with p-tune is: f1 0.5346534653465346, acc 0.5688073394495413
The preditive performance trained on DBLP-GoogleScholar and test on Beer with p-tune is: f1 0.5185185185185185, acc 0.7142857142857143
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with p-tune is: f1 0.29333333333333333, acc 0.43915343915343913
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with p-tune is: f1 0.23628691983122366, acc 0.4699853587115666
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with p-tune is: f1 0.49011857707509887, acc 0.8312254688181422
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with p-tune is: f1 0.9391675560298826, acc 0.9769510715729883
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with p-tune is: f1 0.948938093086308, acc 0.9803204458376872
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with p-tune is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-GoogleScholar and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with p-tune is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Hospital and test on Beer with p-tune is: f1 0.13333333333333333, acc 0.8571428571428571
The preditive performance trained on Hospital and test on Fodors-Zagats with p-tune is: f1 0.0, acc 0.6878306878306878
The preditive performance trained on Hospital and test on Walmart-Amazon with p-tune is: f1 0.03164181465807064, acc 0.8613958028306491
The preditive performance trained on Hospital and test on Amazon-Google with p-tune is: f1 0.011870845204178538, acc 0.894461404273877
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with p-tune is: f1 1.95000195000195e-05, acc 0.7278608976951072
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with p-tune is: f1 0.0011742151929067818, acc 0.8025078369905956
The preditive performance trained on Hospital and test on Hospital with p-tune is: f1 0.9406593406593406, acc 0.9968422899245658
The preditive performance trained on Hospital and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Beer with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Amazon-Google with p-tune is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on DBLP-GoogleScholar with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Hospital with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Buy with p-tune is: f1 0.0, acc 0.8307692307692308
The preditive performance trained on Buy and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on iTunes-Amazon with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Amazon-Google with p-tune is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Restaurant with p-tune is: f1 0.0, acc 0.3488372093023256
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with prefix is: f1 0.8813559322033898, acc 0.9357798165137615
The preditive performance trained on iTunes-Amazon and test on Beer with prefix is: f1 0.2666666666666667, acc 0.15384615384615385
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with prefix is: f1 0.13774104683195593, acc 0.6402116402116402
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with prefix is: f1 0.17247542448614836, acc 0.0961444607125427
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with prefix is: f1 0.2010633156114065, acc 0.27911033580462274
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with prefix is: f1 0.31072056239015816, acc 0.20703598867771936
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with prefix is: f1 0.31555625890172495, acc 0.2467781260884709
The preditive performance trained on iTunes-Amazon and test on Hospital with prefix is: f1 0.0523404983180341, acc 0.028068534003859422
The preditive performance trained on iTunes-Amazon and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Beer and test on Beer with prefix is: f1 0.6956521739130435, acc 0.9230769230769231
The preditive performance trained on Beer and test on Fodors-Zagats with prefix is: f1 0.0, acc 0.8835978835978836
The preditive performance trained on Beer and test on Walmart-Amazon with prefix is: f1 0.0, acc 0.9058077110785749
The preditive performance trained on Beer and test on Amazon-Google with prefix is: f1 0.0, acc 0.8979502834714348
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with prefix is: f1 0.00449438202247191, acc 0.8208653457339264
The preditive performance trained on Beer and test on DBLP-GoogleScholar with prefix is: f1 0.0, acc 0.8136537791710206
The preditive performance trained on Beer and test on Hospital with prefix is: f1 0.045072099126153176, acc 0.6807789018186071
The preditive performance trained on Beer and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Fodors-Zagats and test on Beer with prefix is: f1 0.27184466019417475, acc 0.17582417582417584
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with prefix is: f1 0.9777777777777777, acc 0.9947089947089947
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with prefix is: f1 0.16492242657311865, acc 0.664714494875549
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with prefix is: f1 0.0017094017094017096, acc 0.8966419537723507
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with prefix is: f1 0.643573381950775, acc 0.8418924383340073
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with prefix is: f1 0.06948781950813646, acc 0.7762103796586555
The preditive performance trained on Fodors-Zagats and test on Hospital with prefix is: f1 0.04175665287894871, acc 0.26244079293608563
The preditive performance trained on Fodors-Zagats and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Walmart-Amazon and test on Beer with prefix is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with prefix is: f1 0.0, acc 0.8835978835978836
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with prefix is: f1 0.0, acc 0.9058077110785749
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with prefix is: f1 0.0, acc 0.8979502834714348
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with prefix is: f1 0.0, acc 0.8204609785685403
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with prefix is: f1 0.0, acc 0.8136537791710206
The preditive performance trained on Walmart-Amazon and test on Hospital with prefix is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Walmart-Amazon and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with prefix is: f1 0.5121951219512196, acc 0.6330275229357798
The preditive performance trained on Amazon-Google and test on Beer with prefix is: f1 0.3111111111111111, acc 0.31868131868131866
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with prefix is: f1 0.40430622009569384, acc 0.8201058201058201
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with prefix is: f1 0.15202004808831995, acc 0.43923865300146414
The preditive performance trained on Amazon-Google and test on Amazon-Google with prefix is: f1 0.49145299145299143, acc 0.8979502834714348
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with prefix is: f1 0.591891891891892, acc 0.8778811160533765
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with prefix is: f1 0.41438560055382484, acc 0.8401253918495298
The preditive performance trained on Amazon-Google and test on Hospital with prefix is: f1 0.049167524177076406, acc 0.806444067598386
The preditive performance trained on Amazon-Google and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on DBLP-ACM and test on Beer with prefix is: f1 0.3218390804597701, acc 0.3516483516483517
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with prefix is: f1 0.4583333333333333, acc 0.7248677248677249
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with prefix is: f1 0.2106508875739645, acc 0.34895070766227426
The preditive performance trained on DBLP-ACM and test on Amazon-Google with prefix is: f1 0.2889358703312192, acc 0.5599651112080244
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with prefix is: f1 0.9284210526315789, acc 0.9725030327537404
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with prefix is: f1 0.8904761904761905, acc 0.9599442702890979
The preditive performance trained on DBLP-ACM and test on Hospital with prefix is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-ACM and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with prefix is: f1 0.5052631578947369, acc 0.5688073394495413
The preditive performance trained on DBLP-GoogleScholar and test on Beer with prefix is: f1 0.4117647058823529, acc 0.5604395604395604
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with prefix is: f1 0.4230769230769231, acc 0.6825396825396826
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with prefix is: f1 0.18484848484848485, acc 0.212298682284041
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with prefix is: f1 0.4413231819375164, acc 0.8774531181857829
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with prefix is: f1 0.9109730848861283, acc 0.9652244237767893
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with prefix is: f1 0.917883211678832, acc 0.9686520376175548
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with prefix is: f1 0.028813616156292226, acc 0.4625460499386001
The preditive performance trained on DBLP-GoogleScholar and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Hospital and test on Beer with prefix is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Hospital and test on Fodors-Zagats with prefix is: f1 0.0, acc 0.8835978835978836
The preditive performance trained on Hospital and test on Walmart-Amazon with prefix is: f1 0.0, acc 0.9058077110785749
The preditive performance trained on Hospital and test on Amazon-Google with prefix is: f1 0.0, acc 0.8979502834714348
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with prefix is: f1 0.0, acc 0.8204609785685403
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with prefix is: f1 0.0, acc 0.8136537791710206
The preditive performance trained on Hospital and test on Hospital with prefix is: f1 0.33393829401088926, acc 0.9785392667095492
The preditive performance trained on Hospital and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Beer with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Amazon-Google with prefix is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with prefix is: f1 0.0, acc 0.0008087343307723412
The preditive performance trained on Buy and test on DBLP-GoogleScholar with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Hospital with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Buy with prefix is: f1 0.0, acc 0.9230769230769231
The preditive performance trained on Buy and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Amazon-Google with prefix is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Restaurant with prefix is: f1 0.0, acc 0.6162790697674418
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with prompt is: f1 0.9152542372881356, acc 0.9541284403669725
The preditive performance trained on iTunes-Amazon and test on Beer with prompt is: f1 0.6666666666666667, acc 0.8791208791208791
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with prompt is: f1 0.44, acc 0.8677248677248677
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with prompt is: f1 0.35265544041450775, acc 0.7847730600292826
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with prompt is: f1 0.3572300715157858, acc 0.8386393371129525
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with prompt is: f1 0.14892533811452732, acc 0.7496967246259604
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with prompt is: f1 0.15839991178011192, acc 0.6504702194357367
The preditive performance trained on iTunes-Amazon and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on iTunes-Amazon and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with prompt is: f1 0.8771929824561403, acc 0.9357798165137615
The preditive performance trained on Beer and test on Beer with prompt is: f1 0.896551724137931, acc 0.967032967032967
The preditive performance trained on Beer and test on Fodors-Zagats with prompt is: f1 0.8627450980392156, acc 0.9629629629629629
The preditive performance trained on Beer and test on Walmart-Amazon with prompt is: f1 0.32916265640038495, acc 0.659834065397755
The preditive performance trained on Beer and test on Amazon-Google with prompt is: f1 0.4253819036427733, acc 0.7867422590492804
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with prompt is: f1 0.9119170984455959, acc 0.9656287909421755
The preditive performance trained on Beer and test on DBLP-GoogleScholar with prompt is: f1 0.8118234804329725, acc 0.9212817833507488
The preditive performance trained on Beer and test on Hospital with prompt is: f1 0.024108003857280617, acc 0.651774750014619
The preditive performance trained on Beer and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with prompt is: f1 0.5934065934065934, acc 0.6605504587155964
The preditive performance trained on Fodors-Zagats and test on Beer with prompt is: f1 0.33333333333333337, acc 0.38461538461538464
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with prompt is: f1 1.0, acc 1.0
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with prompt is: f1 0.2933104631217839, acc 0.5978526110297706
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with prompt is: f1 0.40915526191599816, acc 0.8181421718273005
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with prompt is: f1 0.9120370370370371, acc 0.9692680954306511
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with prompt is: f1 0.5209176788124156, acc 0.8763497039359108
The preditive performance trained on Fodors-Zagats and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Fodors-Zagats and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with prompt is: f1 0.75, acc 0.8715596330275229
The preditive performance trained on Walmart-Amazon and test on Beer with prompt is: f1 0.6511627906976745, acc 0.8351648351648352
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with prompt is: f1 0.8108108108108109, acc 0.9629629629629629
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with prompt is: f1 0.7575057736720554, acc 0.9487554904831625
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with prompt is: f1 0.19838056680161945, acc 0.9014391626689926
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with prompt is: f1 0.9096989966555183, acc 0.9672462596037201
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with prompt is: f1 0.8140108534780465, acc 0.9343434343434344
The preditive performance trained on Walmart-Amazon and test on Hospital with prompt is: f1 2.6104633898824968e-05, acc 0.6224782176480907
The preditive performance trained on Walmart-Amazon and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with prompt is: f1 0.7164179104477612, acc 0.8256880733944955
The preditive performance trained on Amazon-Google and test on Beer with prompt is: f1 0.5833333333333334, acc 0.7802197802197802
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with prompt is: f1 0.85, acc 0.9682539682539683
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with prompt is: f1 0.25827022718214426, acc 0.6403123474865788
The preditive performance trained on Amazon-Google and test on Amazon-Google with prompt is: f1 0.7125506072874495, acc 0.9380723942433493
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with prompt is: f1 0.8980432543769309, acc 0.9599676506267691
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with prompt is: f1 0.8597449908925319, acc 0.946360153256705
The preditive performance trained on Amazon-Google and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Amazon-Google and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with prompt is: f1 0.65, acc 0.8715596330275229
The preditive performance trained on DBLP-ACM and test on Beer with prompt is: f1 0.5531914893617021, acc 0.7692307692307693
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with prompt is: f1 0.9767441860465117, acc 0.9947089947089947
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with prompt is: f1 0.2976443274158385, acc 0.690092728160078
The preditive performance trained on DBLP-ACM and test on Amazon-Google with prompt is: f1 0.16396761133603238, acc 0.9049280418665504
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with prompt is: f1 0.9887133182844244, acc 0.9959563283461383
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with prompt is: f1 0.39042632759910245, acc 0.8580633925461512
The preditive performance trained on DBLP-ACM and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-ACM and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with prompt is: f1 0.5744680851063829, acc 0.6330275229357798
The preditive performance trained on DBLP-GoogleScholar and test on Beer with prompt is: f1 0.5098039215686275, acc 0.7252747252747253
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with prompt is: f1 0.65625, acc 0.8835978835978836
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with prompt is: f1 0.24816314474542478, acc 0.6334797462176671
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with prompt is: f1 0.4893964110929853, acc 0.8634976013955517
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with prompt is: f1 0.9575625680087052, acc 0.9842296805499393
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with prompt is: f1 0.9525564256103178, acc 0.9820619993033786
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-GoogleScholar and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with prompt is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Hospital and test on Beer with prompt is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Hospital and test on Fodors-Zagats with prompt is: f1 0.0, acc 0.8783068783068783
The preditive performance trained on Hospital and test on Walmart-Amazon with prompt is: f1 0.003361624692661379, acc 0.7345046364080039
The preditive performance trained on Hospital and test on Amazon-Google with prompt is: f1 0.00038850038850038855, acc 0.8892280854775403
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with prompt is: f1 0.0, acc 0.8139911039223615
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with prompt is: f1 0.0, acc 0.8052943225357019
The preditive performance trained on Hospital and test on Hospital with prompt is: f1 0.7560975609756097, acc 0.9894742997485527
The preditive performance trained on Hospital and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Beer with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with prompt is: f1 0.0, acc 0.0004880429477794046
The preditive performance trained on Buy and test on Amazon-Google with prompt is: f1 0.0, acc 0.002180549498473615
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with prompt is: f1 0.0, acc 0.0016174686615446825
The preditive performance trained on Buy and test on DBLP-GoogleScholar with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Hospital with prompt is: f1 0.0, acc 0.0012279983626688497
The preditive performance trained on Buy and test on Buy with prompt is: f1 0.0, acc 0.8769230769230769
The preditive performance trained on Buy and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on iTunes-Amazon with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Amazon-Google with prompt is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Restaurant with prompt is: f1 0.0, acc 0.3372093023255814
