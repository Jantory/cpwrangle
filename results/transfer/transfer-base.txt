You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with lora is: f1 0.9615384615384615, acc 0.981651376146789
The preditive performance trained on iTunes-Amazon and test on Beer with lora is: f1 0.7222222222222223, acc 0.8901098901098901
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with lora is: f1 0.9, acc 0.9788359788359788
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with lora is: f1 0.37239868565169765, acc 0.7203513909224012
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with lora is: f1 0.4582701062215478, acc 0.8443087658089838
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with lora is: f1 0.7162162162162162, acc 0.9150828952689042
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with lora is: f1 0.704686617730096, acc 0.90891675374434
The preditive performance trained on iTunes-Amazon and test on Hospital with lora is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on iTunes-Amazon and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with lora is: f1 0.7397260273972603, acc 0.8256880733944955
The preditive performance trained on Beer and test on Beer with lora is: f1 0.9032258064516129, acc 0.967032967032967
The preditive performance trained on Beer and test on Fodors-Zagats with lora is: f1 0.8571428571428572, acc 0.9682539682539683
The preditive performance trained on Beer and test on Walmart-Amazon with lora is: f1 0.4145326823435632, acc 0.828696925329429
The preditive performance trained on Beer and test on Amazon-Google with lora is: f1 0.4761904761904762, acc 0.798517226341038
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with lora is: f1 0.8548931383577053, acc 0.947836635665184
The preditive performance trained on Beer and test on DBLP-GoogleScholar with lora is: f1 0.7356619232427771, acc 0.8932427725531173
The preditive performance trained on Beer and test on Hospital with lora is: f1 0.0, acc 0.5743523770539735
The preditive performance trained on Beer and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with lora is: f1 0.6352941176470588, acc 0.7155963302752294
The preditive performance trained on Fodors-Zagats and test on Beer with lora is: f1 0.6829268292682926, acc 0.8571428571428571
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with lora is: f1 1.0, acc 1.0
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with lora is: f1 0.41886269070735094, acc 0.7955100048804294
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with lora is: f1 0.35417398431097064, acc 0.8665503706934148
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with lora is: f1 0.7762237762237761, acc 0.8964820056611403
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with lora is: f1 0.7477941176470587, acc 0.8805294322535702
The preditive performance trained on Fodors-Zagats and test on Hospital with lora is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Fodors-Zagats and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with lora is: f1 0.5714285714285715, acc 0.7522935779816514
The preditive performance trained on Walmart-Amazon and test on Beer with lora is: f1 0.8484848484848484, acc 0.945054945054945
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with lora is: f1 0.9523809523809523, acc 0.9894179894179894
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with lora is: f1 0.8638743455497383, acc 0.974621766715471
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with lora is: f1 0.5819672131147541, acc 0.9110335804622764
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with lora is: f1 0.8702928870292888, acc 0.9498584714921149
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with lora is: f1 0.8247706422018349, acc 0.9334726576105886
The preditive performance trained on Walmart-Amazon and test on Hospital with lora is: f1 0.0, acc 0.9629261446699023
The preditive performance trained on Walmart-Amazon and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with lora is: f1 0.7246376811594204, acc 0.8256880733944955
The preditive performance trained on Amazon-Google and test on Beer with lora is: f1 0.8, acc 0.9230769230769231
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with lora is: f1 0.7719298245614035, acc 0.9312169312169312
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with lora is: f1 0.39617486338797825, acc 0.7842850170815032
The preditive performance trained on Amazon-Google and test on Amazon-Google with lora is: f1 0.7248576850094877, acc 0.9367640645442652
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with lora is: f1 0.8297271872060206, acc 0.9268095430651031
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with lora is: f1 0.8468013468013467, acc 0.9366074538488331
The preditive performance trained on Amazon-Google and test on Hospital with lora is: f1 0.012987012987012988, acc 0.9733348926963336
The preditive performance trained on Amazon-Google and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with lora is: f1 0.7441860465116279, acc 0.8990825688073395
The preditive performance trained on DBLP-ACM and test on Beer with lora is: f1 0.7878787878787878, acc 0.9230769230769231
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with lora is: f1 0.8717948717948718, acc 0.9735449735449735
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with lora is: f1 0.3523509396025056, acc 0.7759882869692533
The preditive performance trained on DBLP-ACM and test on Amazon-Google with lora is: f1 0.28903334537137354, acc 0.9097252507631923
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with lora is: f1 0.9820224719101124, acc 0.9935301253538212
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with lora is: f1 0.6308470290771175, acc 0.8982932776036224
The preditive performance trained on DBLP-ACM and test on Hospital with lora is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-ACM and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with lora is: f1 0.6923076923076924, acc 0.7798165137614679
The preditive performance trained on DBLP-GoogleScholar and test on Beer with lora is: f1 0.8387096774193549, acc 0.945054945054945
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with lora is: f1 0.9166666666666666, acc 0.9788359788359788
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with lora is: f1 0.37095328996065297, acc 0.7808687164470474
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with lora is: f1 0.5801886792452832, acc 0.9223724378543393
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with lora is: f1 0.962800875273523, acc 0.9862515163768703
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with lora is: f1 0.9563197026022305, acc 0.9836293974225009
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with lora is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-GoogleScholar and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with lora is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Hospital and test on Beer with lora is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Hospital and test on Fodors-Zagats with lora is: f1 0.0, acc 0.8835978835978836
The preditive performance trained on Hospital and test on Walmart-Amazon with lora is: f1 0.005829015544041451, acc 0.9009272816007808
The preditive performance trained on Hospital and test on Amazon-Google with lora is: f1 0.0017094017094017096, acc 0.8966419537723507
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with lora is: f1 0.0015015015015015015, acc 0.8200566114031541
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with lora is: f1 0.008411214953271028, acc 0.8143504005572971
The preditive performance trained on Hospital and test on Hospital with lora is: f1 0.9544419134396355, acc 0.9976609554996784
The preditive performance trained on Hospital and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Beer with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with lora is: f1 0.0, acc 0.0004880429477794046
The preditive performance trained on Buy and test on Amazon-Google with lora is: f1 0.0, acc 0.002180549498473615
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on DBLP-GoogleScholar with lora is: f1 0.0, acc 0.00017415534656913968
The preditive performance trained on Buy and test on Hospital with lora is: f1 0.0, acc 0.0014034267001929712
The preditive performance trained on Buy and test on Buy with lora is: f1 0.0, acc 0.9384615384615385
The preditive performance trained on Buy and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on iTunes-Amazon with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Amazon-Google with lora is: f1 0.0, acc 0.0004361098996947231
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Buy with lora is: f1 0.0, acc 0.2
The preditive performance trained on Restaurant and test on Restaurant with lora is: f1 0.0, acc 0.9186046511627907
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with p-tune is: f1 0.8852459016393442, acc 0.9357798165137615
The preditive performance trained on iTunes-Amazon and test on Beer with p-tune is: f1 0.3111111111111111, acc 0.31868131868131866
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with p-tune is: f1 0.8837209302325582, acc 0.9735449735449735
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with p-tune is: f1 0.28444636346190744, acc 0.634455832113226
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with p-tune is: f1 0.33738191632928477, acc 0.7802006105538596
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with p-tune is: f1 0.6926286509040335, acc 0.9106348564496562
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with p-tune is: f1 0.3881019830028329, acc 0.8495297805642633
The preditive performance trained on iTunes-Amazon and test on Hospital with p-tune is: f1 0.050026989848334466, acc 0.029822817379100638
The preditive performance trained on iTunes-Amazon and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with p-tune is: f1 0.07407407407407407, acc 0.7522935779816514
The preditive performance trained on Beer and test on Beer with p-tune is: f1 0.7777777777777778, acc 0.9120879120879121
The preditive performance trained on Beer and test on Fodors-Zagats with p-tune is: f1 0.4, acc 0.746031746031746
The preditive performance trained on Beer and test on Walmart-Amazon with p-tune is: f1 0.178687761749651, acc 0.1386041971693509
The preditive performance trained on Beer and test on Amazon-Google with p-tune is: f1 0.19621052631578947, acc 0.16746620148277366
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with p-tune is: f1 0.5712250712250713, acc 0.7565709664375253
The preditive performance trained on Beer and test on DBLP-GoogleScholar with p-tune is: f1 0.45681188617476715, acc 0.6243469174503657
The preditive performance trained on Beer and test on Hospital with p-tune is: f1 0.0518341307814992, acc 0.02660663119115841
The preditive performance trained on Beer and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with p-tune is: f1 0.9019607843137256, acc 0.9541284403669725
The preditive performance trained on Fodors-Zagats and test on Beer with p-tune is: f1 0.6857142857142857, acc 0.8791208791208791
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with p-tune is: f1 1.0, acc 1.0
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with p-tune is: f1 0.3674943364062535, acc 0.8052708638360175
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with p-tune is: f1 0.15236889310963384, acc 0.8957697339729612
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with p-tune is: f1 0.9042553191489362, acc 0.9636069551152446
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with p-tune is: f1 0.8212058212058212, acc 0.9400905607802159
The preditive performance trained on Fodors-Zagats and test on Hospital with p-tune is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Fodors-Zagats and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with p-tune is: f1 0.5641025641025641, acc 0.8440366972477065
The preditive performance trained on Walmart-Amazon and test on Beer with p-tune is: f1 0.4827586206896552, acc 0.6703296703296703
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with p-tune is: f1 0.9302325581395349, acc 0.9841269841269841
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with p-tune is: f1 0.8108108108108106, acc 0.9658369936554417
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with p-tune is: f1 0.3868336921772036, acc 0.9079808111644134
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with p-tune is: f1 0.875140607424072, acc 0.955115244642135
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with p-tune is: f1 0.6662643331321666, acc 0.9036920933472657
The preditive performance trained on Walmart-Amazon and test on Hospital with p-tune is: f1 0.05227790432801823, acc 0.026840535641190575
The preditive performance trained on Walmart-Amazon and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with p-tune is: f1 0.5625, acc 0.6146788990825688
The preditive performance trained on Amazon-Google and test on Beer with p-tune is: f1 0.45901639344262296, acc 0.6373626373626373
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with p-tune is: f1 0.7547169811320754, acc 0.9312169312169312
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with p-tune is: f1 0.2511013215859031, acc 0.5021961932650073
The preditive performance trained on Amazon-Google and test on Amazon-Google with p-tune is: f1 0.6991869918699187, acc 0.935455734845181
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with p-tune is: f1 0.8424068767908309, acc 0.9332794177112819
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with p-tune is: f1 0.8467640918580376, acc 0.9360849878091257
The preditive performance trained on Amazon-Google and test on Hospital with p-tune is: f1 0.004936669656969542, acc 0.8827553944213788
The preditive performance trained on Amazon-Google and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with p-tune is: f1 0.4117647058823529, acc 0.8165137614678899
The preditive performance trained on DBLP-ACM and test on Beer with p-tune is: f1 0.7777777777777778, acc 0.9120879120879121
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with p-tune is: f1 0.9268292682926829, acc 0.9841269841269841
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with p-tune is: f1 0.40012107615333936, acc 0.867252318204002
The preditive performance trained on DBLP-ACM and test on Amazon-Google with p-tune is: f1 0.27731577731577733, acc 0.9084169210641082
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with p-tune is: f1 0.9832026875699889, acc 0.9939344925192074
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with p-tune is: f1 0.5418918918918919, acc 0.8819226750261233
The preditive performance trained on DBLP-ACM and test on Hospital with p-tune is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-ACM and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with p-tune is: f1 0.8387096774193549, acc 0.908256880733945
The preditive performance trained on DBLP-GoogleScholar and test on Beer with p-tune is: f1 0.923076923076923, acc 0.978021978021978
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with p-tune is: f1 0.846153846153846, acc 0.9576719576719577
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with p-tune is: f1 0.34230229618413927, acc 0.8321132259638848
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with p-tune is: f1 0.5363825363825364, acc 0.9027474923680767
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with p-tune is: f1 0.964835164835165, acc 0.9870602507076426
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with p-tune is: f1 0.9552376557452701, acc 0.9831069313827935
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with p-tune is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-GoogleScholar and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with p-tune is: f1 0.0, acc 0.7247706422018348
The preditive performance trained on Hospital and test on Beer with p-tune is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Hospital and test on Fodors-Zagats with p-tune is: f1 0.0, acc 0.8783068783068783
The preditive performance trained on Hospital and test on Walmart-Amazon with p-tune is: f1 0.05782753515914137, acc 0.7359687652513421
The preditive performance trained on Hospital and test on Amazon-Google with p-tune is: f1 0.03924646781789639, acc 0.8896641953772351
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with p-tune is: f1 0.045566619250829776, acc 0.7169429842296805
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with p-tune is: f1 0.020633282187194867, acc 0.726924416579589
The preditive performance trained on Hospital and test on Hospital with p-tune is: f1 0.9544419134396355, acc 0.9976609554996784
The preditive performance trained on Hospital and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with p-tune is: f1 0.0, acc 0.009174311926605505
The preditive performance trained on Buy and test on Beer with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with p-tune is: f1 0.0, acc 0.0004880429477794046
The preditive performance trained on Buy and test on Amazon-Google with p-tune is: f1 0.0, acc 0.0030527692978630614
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with p-tune is: f1 0.0, acc 0.0008087343307723412
The preditive performance trained on Buy and test on DBLP-GoogleScholar with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Hospital with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Buy with p-tune is: f1 0.0, acc 0.8615384615384616
The preditive performance trained on Buy and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on iTunes-Amazon with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Amazon-Google with p-tune is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Restaurant with p-tune is: f1 0.0, acc 0.5813953488372093
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with prefix is: f1 0.9019607843137256, acc 0.9541284403669725
The preditive performance trained on iTunes-Amazon and test on Beer with prefix is: f1 0.2666666666666667, acc 0.15384615384615385
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with prefix is: f1 0.45454545454545453, acc 0.8835978835978836
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with prefix is: f1 0.1741468643916384, acc 0.2235236700829673
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with prefix is: f1 0.16738360323886642, acc 0.26733536851286527
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with prefix is: f1 0.551130247578041, acc 0.8313788920339669
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with prefix is: f1 0.5030364372469636, acc 0.8289794496691049
The preditive performance trained on iTunes-Amazon and test on Hospital with prefix is: f1 0.0031028328500307557, acc 0.8928132857727619
The preditive performance trained on iTunes-Amazon and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with prefix is: f1 0.4153846153846154, acc 0.30275229357798167
The preditive performance trained on Beer and test on Beer with prefix is: f1 0.8571428571428571, acc 0.9560439560439561
The preditive performance trained on Beer and test on Fodors-Zagats with prefix is: f1 0.2085308056872038, acc 0.1164021164021164
The preditive performance trained on Beer and test on Walmart-Amazon with prefix is: f1 0.17783437253007817, acc 0.5192776964372865
The preditive performance trained on Beer and test on Amazon-Google with prefix is: f1 0.1883061049011178, acc 0.17662450937636284
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with prefix is: f1 0.3680066307501036, acc 0.3833400727860898
The preditive performance trained on Beer and test on DBLP-GoogleScholar with prefix is: f1 0.36354309165526677, acc 0.35179380006966215
The preditive performance trained on Beer and test on Hospital with prefix is: f1 0.052209992508499975, acc 0.03824337758025846
The preditive performance trained on Beer and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with prefix is: f1 0.40601503759398494, acc 0.27522935779816515
The preditive performance trained on Fodors-Zagats and test on Beer with prefix is: f1 0.2666666666666667, acc 0.15384615384615385
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with prefix is: f1 1.0, acc 1.0
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with prefix is: f1 0.22664255575647982, acc 0.3738408979990239
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with prefix is: f1 0.2102547042666803, acc 0.5979066724814653
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with prefix is: f1 0.31247790738776954, acc 0.2135058633238981
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with prefix is: f1 0.32295131539159355, acc 0.22013235806339254
The preditive performance trained on Fodors-Zagats and test on Hospital with prefix is: f1 0.031210336992390893, acc 0.6276825916613064
The preditive performance trained on Fodors-Zagats and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with prefix is: f1 0.19999999999999998, acc 0.7798165137614679
The preditive performance trained on Walmart-Amazon and test on Beer with prefix is: f1 0.3010752688172043, acc 0.2857142857142857
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with prefix is: f1 0.0, acc 0.8835978835978836
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with prefix is: f1 0.6849999999999999, acc 0.9385065885797951
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with prefix is: f1 0.2180293501048218, acc 0.8970780636720453
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with prefix is: f1 0.5866666666666667, acc 0.8871815608572584
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with prefix is: f1 0.3015576323987539, acc 0.8380355276907001
The preditive performance trained on Walmart-Amazon and test on Hospital with prefix is: f1 0.008883663204650859, acc 0.8484883924916672
The preditive performance trained on Walmart-Amazon and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with prefix is: f1 0.7297297297297298, acc 0.8165137614678899
The preditive performance trained on Amazon-Google and test on Beer with prefix is: f1 0.35, acc 0.42857142857142855
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with prefix is: f1 0.4489795918367347, acc 0.7142857142857143
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with prefix is: f1 0.30534111779725553, acc 0.7066861883845779
The preditive performance trained on Amazon-Google and test on Amazon-Google with prefix is: f1 0.6573146292585169, acc 0.9254252071522023
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with prefix is: f1 0.8529980657640232, acc 0.938536190861302
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with prefix is: f1 0.7524475524475526, acc 0.9075235109717869
The preditive performance trained on Amazon-Google and test on Hospital with prefix is: f1 0.035509393344208086, acc 0.5879188351558389
The preditive performance trained on Amazon-Google and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with prefix is: f1 0.6749999999999999, acc 0.7614678899082569
The preditive performance trained on DBLP-ACM and test on Beer with prefix is: f1 0.4666666666666667, acc 0.6483516483516484
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with prefix is: f1 0.43749999999999994, acc 0.7142857142857143
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with prefix is: f1 0.18909090909090912, acc 0.23816495851634945
The preditive performance trained on DBLP-ACM and test on Amazon-Google with prefix is: f1 0.3273040482342808, acc 0.6593981683384212
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with prefix is: f1 0.9720670391061451, acc 0.9898908208653457
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with prefix is: f1 0.8571428571428571, acc 0.9479275513758273
The preditive performance trained on DBLP-ACM and test on Hospital with prefix is: f1 0.00027259736304644595, acc 0.9142740190632127
The preditive performance trained on DBLP-ACM and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with prefix is: f1 0.5567010309278351, acc 0.6055045871559633
The preditive performance trained on DBLP-GoogleScholar and test on Beer with prefix is: f1 0.37333333333333335, acc 0.4835164835164835
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with prefix is: f1 0.2802547770700637, acc 0.4021164021164021
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with prefix is: f1 0.20214450201496836, acc 0.42850170815031724
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with prefix is: f1 0.38933191564770514, acc 0.7719145224596599
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with prefix is: f1 0.9688888888888889, acc 0.9886777193691872
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with prefix is: f1 0.9467345993515517, acc 0.979972135144549
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with prefix is: f1 0.039107355649442094, acc 0.47728203029062627
The preditive performance trained on DBLP-GoogleScholar and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Hospital and test on Beer with prefix is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Hospital and test on Fodors-Zagats with prefix is: f1 0.0, acc 0.8835978835978836
The preditive performance trained on Hospital and test on Walmart-Amazon with prefix is: f1 0.005472797927461141, acc 0.7623230844314299
The preditive performance trained on Hospital and test on Amazon-Google with prefix is: f1 0.02097902097902098, acc 0.891408634976014
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with prefix is: f1 0.006006006006006006, acc 0.8208653457339264
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with prefix is: f1 0.0036635514018691596, acc 0.81173807035876
The preditive performance trained on Hospital and test on Hospital with prefix is: f1 0.9123222748815166, acc 0.995672767674405
The preditive performance trained on Hospital and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Beer with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Amazon-Google with prefix is: f1 0.0, acc 0.0034888791975577847
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on DBLP-GoogleScholar with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Hospital with prefix is: f1 0.0, acc 0.0014034267001929712
The preditive performance trained on Buy and test on Buy with prefix is: f1 0.0, acc 0.9230769230769231
The preditive performance trained on Buy and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Amazon-Google with prefix is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Restaurant with prefix is: f1 0.0, acc 0.5930232558139535
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with prompt is: f1 0.9310344827586207, acc 0.963302752293578
The preditive performance trained on iTunes-Amazon and test on Beer with prompt is: f1 0.8387096774193549, acc 0.945054945054945
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with prompt is: f1 0.9523809523809523, acc 0.9894179894179894
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with prompt is: f1 0.2968967630508663, acc 0.8862859931673988
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with prompt is: f1 0.2704739704739705, acc 0.9014391626689926
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with prompt is: f1 0.8388941849380362, acc 0.9316619490497372
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with prompt is: f1 0.8319327731092436, acc 0.9303378613723441
The preditive performance trained on iTunes-Amazon and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on iTunes-Amazon and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with prompt is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Beer and test on Beer with prompt is: f1 0.7200000000000001, acc 0.9230769230769231
The preditive performance trained on Beer and test on Fodors-Zagats with prompt is: f1 0.08695652173913045, acc 0.8888888888888888
The preditive performance trained on Beer and test on Walmart-Amazon with prompt is: f1 0.3730883969225938, acc 0.8511469009272816
The preditive performance trained on Beer and test on Amazon-Google with prompt is: f1 0.19260864331286867, acc 0.9018752725686873
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with prompt is: f1 0.7682119205298014, acc 0.9292357460574201
The preditive performance trained on Beer and test on DBLP-GoogleScholar with prompt is: f1 0.5589105979869745, acc 0.8702542668059909
The preditive performance trained on Beer and test on Hospital with prompt is: f1 0.015227642288307752, acc 0.7263317934623706
The preditive performance trained on Beer and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with prompt is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Fodors-Zagats and test on Beer with prompt is: f1 0.7777777777777778, acc 0.9120879120879121
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with prompt is: f1 0.9, acc 0.9788359788359788
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with prompt is: f1 0.25018504811250925, acc 0.8589555880917521
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with prompt is: f1 0.29739470703326126, acc 0.8918447448757086
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with prompt is: f1 0.8967082860385925, acc 0.9632025879498585
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with prompt is: f1 0.617948717948718, acc 0.8962034134447927
The preditive performance trained on Fodors-Zagats and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Fodors-Zagats and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with prompt is: f1 0.4122137404580153, acc 0.29357798165137616
The preditive performance trained on Walmart-Amazon and test on Beer with prompt is: f1 0.2745098039215686, acc 0.18681318681318682
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with prompt is: f1 0.9523809523809523, acc 0.9894179894179894
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with prompt is: f1 0.7650000000000001, acc 0.954123962908736
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with prompt is: f1 0.4411359250068927, acc 0.8809419973833406
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with prompt is: f1 0.8255481410867492, acc 0.9260008087343308
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with prompt is: f1 0.7375000000000002, acc 0.8756530825496343
The preditive performance trained on Walmart-Amazon and test on Hospital with prompt is: f1 7.486242120348217e-05, acc 0.8072042570609906
The preditive performance trained on Walmart-Amazon and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with prompt is: f1 0.8214285714285715, acc 0.908256880733945
The preditive performance trained on Amazon-Google and test on Beer with prompt is: f1 0.7567567567567568, acc 0.9010989010989011
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with prompt is: f1 0.84, acc 0.9576719576719577
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with prompt is: f1 0.35462555066079293, acc 0.714006832601269
The preditive performance trained on Amazon-Google and test on Amazon-Google with prompt is: f1 0.702258726899384, acc 0.9367640645442652
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with prompt is: f1 0.892116182572614, acc 0.9579458147998382
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with prompt is: f1 0.8711068519405845, acc 0.9531522117729014
The preditive performance trained on Amazon-Google and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Amazon-Google and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with prompt is: f1 0.819672131147541, acc 0.8990825688073395
The preditive performance trained on DBLP-ACM and test on Beer with prompt is: f1 0.4666666666666667, acc 0.6483516483516484
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with prompt is: f1 0.9545454545454546, acc 0.9894179894179894
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with prompt is: f1 0.23669151368389726, acc 0.5031722791605662
The preditive performance trained on DBLP-ACM and test on Amazon-Google with prompt is: f1 0.4747393386136841, acc 0.9044919319668556
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with prompt is: f1 0.9844097995545658, acc 0.9943388596845936
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with prompt is: f1 0.5290933694181326, acc 0.8787878787878788
The preditive performance trained on DBLP-ACM and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-ACM and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with prompt is: f1 0.9019607843137256, acc 0.9541284403669725
The preditive performance trained on DBLP-GoogleScholar and test on Beer with prompt is: f1 0.5714285714285714, acc 0.9010989010989011
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with prompt is: f1 1.0, acc 1.0
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with prompt is: f1 0.3817199879376045, acc 0.8365056124938994
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with prompt is: f1 0.5258426966292135, acc 0.9079808111644134
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with prompt is: f1 0.9606126914660831, acc 0.9854427820460978
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with prompt is: f1 0.9536909674461256, acc 0.9824103099965169
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-GoogleScholar and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with prompt is: f1 0.0, acc 0.7431192660550459
The preditive performance trained on Hospital and test on Beer with prompt is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Hospital and test on Fodors-Zagats with prompt is: f1 0.0, acc 0.8835978835978836
The preditive performance trained on Hospital and test on Walmart-Amazon with prompt is: f1 0.00511036979203634, acc 0.7750122010736945
The preditive performance trained on Hospital and test on Amazon-Google with prompt is: f1 0.01465201465201465, acc 0.8940252943741823
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with prompt is: f1 0.0, acc 0.8180347755762232
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with prompt is: f1 0.0012940330697340044, acc 0.8124346917450366
The preditive performance trained on Hospital and test on Hospital with prompt is: f1 0.966702470461869, acc 0.9981872405122507
The preditive performance trained on Hospital and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Beer with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with prompt is: f1 0.0, acc 0.0009760858955588092
The preditive performance trained on Buy and test on Amazon-Google with prompt is: f1 0.0, acc 0.0004361098996947231
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on DBLP-GoogleScholar with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Hospital with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Buy with prompt is: f1 0.0, acc 0.8615384615384616
The preditive performance trained on Buy and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on iTunes-Amazon with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Amazon-Google with prompt is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Restaurant with prompt is: f1 0.0, acc 0.3372093023255814
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with finetune is: f1 0.912280701754386, acc 0.9541284403669725
The preditive performance trained on iTunes-Amazon and test on Beer with finetune is: f1 0.5714285714285715, acc 0.7692307692307693
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with finetune is: f1 0.9361702127659575, acc 0.9841269841269841
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with finetune is: f1 0.17952314165497896, acc 0.14348462664714495
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with finetune is: f1 0.2523041474654378, acc 0.43392935019624945
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with finetune is: f1 0.6825518831667947, acc 0.8329963606955115
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with finetune is: f1 0.6360837438423644, acc 0.7941483803552769
The preditive performance trained on iTunes-Amazon and test on Hospital with finetune is: f1 0.04577642985796844, acc 0.08098941582363604
The preditive performance trained on iTunes-Amazon and test on Buy with finetune is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with finetune is: f1 0.7761194029850746, acc 0.8623853211009175
The preditive performance trained on Beer and test on Beer with finetune is: f1 0.9333333333333333, acc 0.978021978021978
The preditive performance trained on Beer and test on Fodors-Zagats with finetune is: f1 0.9523809523809523, acc 0.9894179894179894
The preditive performance trained on Beer and test on Walmart-Amazon with finetune is: f1 0.3235294117647059, acc 0.6857003416300634
The preditive performance trained on Beer and test on Amazon-Google with finetune is: f1 0.4358407079646017, acc 0.7775839511556912
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with finetune is: f1 0.9136316337148803, acc 0.9664375252729478
The preditive performance trained on Beer and test on DBLP-GoogleScholar with finetune is: f1 0.8433945756780403, acc 0.937652385928248
The preditive performance trained on Beer and test on Hospital with finetune is: f1 0.006340759111432598, acc 0.8898894801473598
The preditive performance trained on Beer and test on Buy with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with finetune is: f1 0.8524590163934426, acc 0.9174311926605505
The preditive performance trained on Fodors-Zagats and test on Beer with finetune is: f1 0.8484848484848484, acc 0.945054945054945
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with finetune is: f1 0.9767441860465117, acc 0.9947089947089947
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with finetune is: f1 0.3597883597883598, acc 0.7047340165934602
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with finetune is: f1 0.3148897885739991, acc 0.9010030527692978
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with finetune is: f1 0.9249999999999999, acc 0.9708855640921957
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with finetune is: f1 0.8908212560386474, acc 0.9606408916753745
The preditive performance trained on Fodors-Zagats and test on Hospital with finetune is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Fodors-Zagats and test on Buy with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with finetune is: f1 0.3898635477582846, acc 0.7614678899082569
The preditive performance trained on Walmart-Amazon and test on Beer with finetune is: f1 0.8235294117647058, acc 0.9340659340659341
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with finetune is: f1 0.8421052631578948, acc 0.9682539682539683
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with finetune is: f1 0.7769028871391076, acc 0.9585163494387506
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with finetune is: f1 0.5127020785219399, acc 0.9079808111644134
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with finetune is: f1 0.815311004784689, acc 0.9219571370804691
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with finetune is: f1 0.763397371081901, acc 0.9184952978056427
The preditive performance trained on Walmart-Amazon and test on Hospital with finetune is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Walmart-Amazon and test on Buy with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with finetune is: f1 0.6923076923076923, acc 0.8532110091743119
The preditive performance trained on Amazon-Google and test on Beer with finetune is: f1 0.7368421052631579, acc 0.8901098901098901
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with finetune is: f1 0.7200000000000001, acc 0.9259259259259259
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with finetune is: f1 0.2927158137139048, acc 0.7076622742801366
The preditive performance trained on Amazon-Google and test on Amazon-Google with finetune is: f1 0.689108910891089, acc 0.9315307457479285
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with finetune is: f1 0.8041237113402062, acc 0.9154872624342903
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with finetune is: f1 0.8329773601025203, acc 0.9319052594914664
The preditive performance trained on Amazon-Google and test on Hospital with finetune is: f1 0.005234644881306352, acc 0.7560376586164552
The preditive performance trained on Amazon-Google and test on Buy with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with finetune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with finetune is: f1 0.5897435897435898, acc 0.7064220183486238
The preditive performance trained on DBLP-ACM and test on Beer with finetune is: f1 0.27368421052631575, acc 0.24175824175824176
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with finetune is: f1 0.45161290322580644, acc 0.7301587301587301
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with finetune is: f1 0.18752778039134257, acc 0.29233772571986333
The preditive performance trained on DBLP-ACM and test on Amazon-Google with finetune is: f1 0.2903557534658556, acc 0.664631487134758
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with finetune is: f1 0.9853107344632768, acc 0.9947432268499797
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with finetune is: f1 0.526530612244898, acc 0.8787878787878788
The preditive performance trained on DBLP-ACM and test on Hospital with finetune is: f1 0.00039902000686314415, acc 0.9577802467691948
The preditive performance trained on DBLP-ACM and test on Buy with finetune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with finetune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with finetune is: f1 0.5, acc 0.5045871559633027
The preditive performance trained on DBLP-GoogleScholar and test on Beer with finetune is: f1 0.3661971830985915, acc 0.5054945054945055
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with finetune is: f1 0.25882352941176473, acc 0.3333333333333333
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with finetune is: f1 0.20546068934444697, acc 0.49194729136163984
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with finetune is: f1 0.324653813025906, acc 0.7950283471434801
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with finetune is: f1 0.9645232815964524, acc 0.9870602507076426
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with finetune is: f1 0.9397701149425287, acc 0.9771856495994427
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with finetune is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-GoogleScholar and test on Buy with finetune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with finetune is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Hospital and test on Beer with finetune is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Hospital and test on Fodors-Zagats with finetune is: f1 0.0, acc 0.8835978835978836
The preditive performance trained on Hospital and test on Walmart-Amazon with finetune is: f1 0.020024530049310405, acc 0.8243045387994143
The preditive performance trained on Hospital and test on Amazon-Google with finetune is: f1 0.002136752136752137, acc 0.8927169646750981
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with finetune is: f1 0.00026497085320614734, acc 0.8143954710877477
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with finetune is: f1 0.004063388866314506, acc 0.8091257401602229
The preditive performance trained on Hospital and test on Hospital with finetune is: f1 0.9496567505720824, acc 0.9974270510496462
The preditive performance trained on Hospital and test on Buy with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Beer with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with finetune is: f1 0.0, acc 0.0009760858955588092
The preditive performance trained on Buy and test on Amazon-Google with finetune is: f1 0.0, acc 0.00436109899694723
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with finetune is: f1 0.0, acc 0.002426202992317024
The preditive performance trained on Buy and test on DBLP-GoogleScholar with finetune is: f1 0.0, acc 0.00017415534656913968
The preditive performance trained on Buy and test on Hospital with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Buy with finetune is: f1 0.0, acc 0.9538461538461539
The preditive performance trained on Buy and test on Restaurant with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on iTunes-Amazon with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with finetune is: f1 0.0, acc 0.0009760858955588092
The preditive performance trained on Restaurant and test on Amazon-Google with finetune is: f1 0.0, acc 0.0004361098996947231
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with finetune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Buy with finetune is: f1 0.0, acc 0.06153846153846154
The preditive performance trained on Restaurant and test on Restaurant with finetune is: f1 0.0, acc 0.9186046511627907
