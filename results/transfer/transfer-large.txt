You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with lora is: f1 0.9629629629629629, acc 0.981651376146789
The preditive performance trained on iTunes-Amazon and test on Beer with lora is: f1 0.8750000000000001, acc 0.9560439560439561
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with lora is: f1 1.0, acc 1.0
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with lora is: f1 0.35645472061657035, acc 0.6739873108833577
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with lora is: f1 0.6181015452538632, acc 0.9245529873528129
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with lora is: f1 0.8897795591182365, acc 0.9555196118075212
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with lora is: f1 0.832204065364687, acc 0.9266805990943922
The preditive performance trained on iTunes-Amazon and test on Hospital with lora is: f1 0.0006346001476808743, acc 0.5657563885152915
The preditive performance trained on iTunes-Amazon and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with lora is: f1 0.9473684210526316, acc 0.9724770642201835
The preditive performance trained on Beer and test on Beer with lora is: f1 0.9333333333333333, acc 0.978021978021978
The preditive performance trained on Beer and test on Fodors-Zagats with lora is: f1 1.0, acc 1.0
The preditive performance trained on Beer and test on Walmart-Amazon with lora is: f1 0.6292134831460674, acc 0.9033674963396779
The preditive performance trained on Beer and test on Amazon-Google with lora is: f1 0.5362134688691234, acc 0.840819886611426
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with lora is: f1 0.905894519131334, acc 0.9632025879498585
The preditive performance trained on Beer and test on DBLP-GoogleScholar with lora is: f1 0.8540896013152487, acc 0.9381748519679555
The preditive performance trained on Beer and test on Hospital with lora is: f1 0.013592978078354587, acc 0.41956610724519033
The preditive performance trained on Beer and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with lora is: f1 0.6842105263157895, acc 0.7798165137614679
The preditive performance trained on Fodors-Zagats and test on Beer with lora is: f1 0.2666666666666667, acc 0.15384615384615385
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with lora is: f1 1.0, acc 1.0
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with lora is: f1 0.2053191489361702, acc 0.2708638360175695
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with lora is: f1 0.13823142669296518, acc 0.7697339729611862
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with lora is: f1 0.6543846720707444, acc 0.810351799433886
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with lora is: f1 0.5070652173913044, acc 0.6840822013235807
The preditive performance trained on Fodors-Zagats and test on Hospital with lora is: f1 0.0, acc 0.1563651248465002
The preditive performance trained on Fodors-Zagats and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with lora is: f1 0.5567010309278351, acc 0.6055045871559633
The preditive performance trained on Walmart-Amazon and test on Beer with lora is: f1 0.8750000000000001, acc 0.9560439560439561
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with lora is: f1 0.9166666666666666, acc 0.9788359788359788
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with lora is: f1 0.8264058679706602, acc 0.9653489507076622
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with lora is: f1 0.6104129263913823, acc 0.9053641517662451
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with lora is: f1 0.8571428571428571, acc 0.9409623938536191
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with lora is: f1 0.8263624841571611, acc 0.9284221525600836
The preditive performance trained on Walmart-Amazon and test on Hospital with lora is: f1 0.0, acc 0.8825214899713467
The preditive performance trained on Walmart-Amazon and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with lora is: f1 0.8518518518518519, acc 0.926605504587156
The preditive performance trained on Amazon-Google and test on Beer with lora is: f1 0.9032258064516129, acc 0.967032967032967
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with lora is: f1 0.8571428571428572, acc 0.9682539682539683
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with lora is: f1 0.49360146252285186, acc 0.864812103465105
The preditive performance trained on Amazon-Google and test on Amazon-Google with lora is: f1 0.7421150278293135, acc 0.9393807239424335
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with lora is: f1 0.8704253214638971, acc 0.9470279013344116
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with lora is: f1 0.8564036222509702, acc 0.9420062695924765
The preditive performance trained on Amazon-Google and test on Hospital with lora is: f1 0.0007762480233723429, acc 0.8910005262850126
The preditive performance trained on Amazon-Google and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with lora is: f1 0.7692307692307692, acc 0.8899082568807339
The preditive performance trained on DBLP-ACM and test on Beer with lora is: f1 0.6829268292682926, acc 0.8571428571428571
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with lora is: f1 0.9268292682926829, acc 0.9841269841269841
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with lora is: f1 0.3139866793529971, acc 0.6481210346510493
The preditive performance trained on DBLP-ACM and test on Amazon-Google with lora is: f1 0.4327979712595097, acc 0.902311382468382
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with lora is: f1 0.9680264608599779, acc 0.9882733522038011
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with lora is: f1 0.8896551724137932, acc 0.9609892023685127
The preditive performance trained on DBLP-ACM and test on Hospital with lora is: f1 0.011217725861029992, acc 0.9716975615461084
The preditive performance trained on DBLP-ACM and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with lora is: f1 0.7605633802816901, acc 0.8440366972477065
The preditive performance trained on DBLP-GoogleScholar and test on Beer with lora is: f1 0.9333333333333333, acc 0.978021978021978
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with lora is: f1 0.9767441860465117, acc 0.9947089947089947
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with lora is: f1 0.4371428571428571, acc 0.8077110785749146
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with lora is: f1 0.6275229357798164, acc 0.9114696903619712
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with lora is: f1 0.9373007438894794, acc 0.9761423372422159
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with lora is: f1 0.951131221719457, acc 0.9811912225705329
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with lora is: f1 0.00010936994164019914, acc 0.9155020174258816
The preditive performance trained on DBLP-GoogleScholar and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with lora is: f1 0.39705882352941174, acc 0.24770642201834864
The preditive performance trained on Hospital and test on Beer with lora is: f1 0.2745098039215686, acc 0.18681318681318682
The preditive performance trained on Hospital and test on Fodors-Zagats with lora is: f1 0.0928030303030303, acc 0.7037037037037037
The preditive performance trained on Hospital and test on Walmart-Amazon with lora is: f1 0.15679164762950937, acc 0.5095168374816984
The preditive performance trained on Hospital and test on Amazon-Google with lora is: f1 0.16794981091656283, acc 0.21631051024858264
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with lora is: f1 0.6638655462184875, acc 0.8382531338455318
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with lora is: f1 0.5240223463687151, acc 0.851619644723093
The preditive performance trained on Hospital and test on Hospital with lora is: f1 0.9945235487404162, acc 0.9997076194374598
The preditive performance trained on Hospital and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Beer with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with lora is: f1 0.0, acc 0.0004880429477794046
The preditive performance trained on Buy and test on Amazon-Google with lora is: f1 0.0, acc 0.0013083296990841692
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with lora is: f1 0.0, acc 0.0008087343307723412
The preditive performance trained on Buy and test on DBLP-GoogleScholar with lora is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Hospital with lora is: f1 0.0, acc 0.0014034267001929712
The preditive performance trained on Buy and test on Buy with lora is: f1 0.0, acc 0.9384615384615385
The preditive performance trained on Buy and test on Restaurant with lora is: f1 0.0, acc 0.011627906976744186
The preditive performance trained on Restaurant and test on iTunes-Amazon with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Amazon-Google with lora is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with lora is: f1 0.0, acc 0.003976375650546752
The preditive performance trained on Restaurant and test on Buy with lora is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Restaurant with lora is: f1 0.0, acc 0.9069767441860465
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with p-tune is: f1 0.9642857142857143, acc 0.981651376146789
The preditive performance trained on iTunes-Amazon and test on Beer with p-tune is: f1 0.4210526315789474, acc 0.6373626373626373
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with p-tune is: f1 0.2802547770700637, acc 0.4021164021164021
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with p-tune is: f1 0.18078561287269285, acc 0.15519765739385066
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with p-tune is: f1 0.35251141552511417, acc 0.6907980811164414
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with p-tune is: f1 0.9009384775808135, acc 0.9615851192883138
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with p-tune is: f1 0.7574234810415714, acc 0.9075235109717869
The preditive performance trained on iTunes-Amazon and test on Hospital with p-tune is: f1 2.7404392924185747e-06, acc 0.8802993976960412
The preditive performance trained on iTunes-Amazon and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with p-tune is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Beer and test on Beer with p-tune is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Beer and test on Fodors-Zagats with p-tune is: f1 0.0, acc 0.8835978835978836
The preditive performance trained on Beer and test on Walmart-Amazon with p-tune is: f1 0.0, acc 0.9058077110785749
The preditive performance trained on Beer and test on Amazon-Google with p-tune is: f1 0.0, acc 0.8979502834714348
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with p-tune is: f1 0.0, acc 0.8204609785685403
The preditive performance trained on Beer and test on DBLP-GoogleScholar with p-tune is: f1 0.0, acc 0.8136537791710206
The preditive performance trained on Beer and test on Hospital with p-tune is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Beer and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with p-tune is: f1 0.48648648648648646, acc 0.8256880733944955
The preditive performance trained on Fodors-Zagats and test on Beer with p-tune is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with p-tune is: f1 0.7804878048780488, acc 0.9523809523809523
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with p-tune is: f1 0.17729441337916174, acc 0.8282088823816496
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with p-tune is: f1 0.06500224921277553, acc 0.8962058438726559
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with p-tune is: f1 0.04405286343612334, acc 0.8245046502224019
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with p-tune is: f1 0.00046728971962616824, acc 0.8133054684778823
The preditive performance trained on Fodors-Zagats and test on Hospital with p-tune is: f1 0.003008462855739855, acc 0.9347406584410268
The preditive performance trained on Fodors-Zagats and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with p-tune is: f1 0.6585365853658536, acc 0.7431192660550459
The preditive performance trained on Walmart-Amazon and test on Beer with p-tune is: f1 0.9032258064516129, acc 0.967032967032967
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with p-tune is: f1 1.0, acc 1.0
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with p-tune is: f1 0.8623376623376622, acc 0.9741337237676916
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with p-tune is: f1 0.6220095693779905, acc 0.8966419537723507
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with p-tune is: f1 0.8828282828282829, acc 0.9530934088152042
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with p-tune is: f1 0.8267241379310345, acc 0.9299895506792059
The preditive performance trained on Walmart-Amazon and test on Hospital with p-tune is: f1 0.008983180924923501, acc 0.2567686100228057
The preditive performance trained on Walmart-Amazon and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with p-tune is: f1 0.6222222222222222, acc 0.8440366972477065
The preditive performance trained on Amazon-Google and test on Beer with p-tune is: f1 0.7777777777777778, acc 0.9120879120879121
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with p-tune is: f1 0.88, acc 0.9682539682539683
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with p-tune is: f1 0.41000000000000003, acc 0.769643728648121
The preditive performance trained on Amazon-Google and test on Amazon-Google with p-tune is: f1 0.7388781431334622, acc 0.9411251635412123
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with p-tune is: f1 0.8540218470705064, acc 0.940558026688233
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with p-tune is: f1 0.7999999999999999, acc 0.921455938697318
The preditive performance trained on Amazon-Google and test on Hospital with p-tune is: f1 0.001545103385594183, acc 0.7865037132331443
The preditive performance trained on Amazon-Google and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with p-tune is: f1 0.3386243386243386, acc 0.7706422018348624
The preditive performance trained on DBLP-ACM and test on Beer with p-tune is: f1 0.631578947368421, acc 0.8461538461538461
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with p-tune is: f1 0.8571428571428572, acc 0.9682539682539683
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with p-tune is: f1 0.2441827602449364, acc 0.769643728648121
The preditive performance trained on DBLP-ACM and test on Amazon-Google with p-tune is: f1 0.1302897644361059, acc 0.9018752725686873
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with p-tune is: f1 0.937720329024677, acc 0.978568540234533
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with p-tune is: f1 0.3793103448275862, acc 0.8557993730407524
The preditive performance trained on DBLP-ACM and test on Hospital with p-tune is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-ACM and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with p-tune is: f1 0.423728813559322, acc 0.3761467889908257
The preditive performance trained on DBLP-GoogleScholar and test on Beer with p-tune is: f1 0.6153846153846153, acc 0.8901098901098901
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with p-tune is: f1 0.24691358024691357, acc 0.3544973544973545
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with p-tune is: f1 0.21053377137782428, acc 0.5773548072230357
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with p-tune is: f1 0.3288967182096953, acc 0.9027474923680767
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with p-tune is: f1 0.7753303964757708, acc 0.8968863728265265
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with p-tune is: f1 0.8090062111801244, acc 0.9143155694879833
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with p-tune is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-GoogleScholar and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with p-tune is: f1 0.0, acc 0.5963302752293578
The preditive performance trained on Hospital and test on Beer with p-tune is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Hospital and test on Fodors-Zagats with p-tune is: f1 0.0, acc 0.8201058201058201
The preditive performance trained on Hospital and test on Walmart-Amazon with p-tune is: f1 0.0140886068580078, acc 0.8731088335773548
The preditive performance trained on Hospital and test on Amazon-Google with p-tune is: f1 0.016949152542372885, acc 0.8988225032708242
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with p-tune is: f1 1.0598834128245891e-05, acc 0.64941366761019
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with p-tune is: f1 4.847089474242264e-05, acc 0.7075931731104145
The preditive performance trained on Hospital and test on Hospital with p-tune is: f1 0.952054794520548, acc 0.9975440032746623
The preditive performance trained on Hospital and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Beer with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with p-tune is: f1 0.0, acc 0.0004880429477794046
The preditive performance trained on Buy and test on Amazon-Google with p-tune is: f1 0.0, acc 0.0034888791975577847
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with p-tune is: f1 0.0, acc 0.0004043671653861706
The preditive performance trained on Buy and test on DBLP-GoogleScholar with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Hospital with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Buy with p-tune is: f1 0.0, acc 0.8615384615384616
The preditive performance trained on Buy and test on Restaurant with p-tune is: f1 0.0, acc 0.011627906976744186
The preditive performance trained on Restaurant and test on iTunes-Amazon with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with p-tune is: f1 0.0, acc 0.0004880429477794046
The preditive performance trained on Restaurant and test on Amazon-Google with p-tune is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with p-tune is: f1 0.0, acc 0.0012279983626688497
The preditive performance trained on Restaurant and test on Buy with p-tune is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Restaurant with p-tune is: f1 0.0, acc 0.7558139534883721
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with prefix is: f1 0.9433962264150944, acc 0.9724770642201835
The preditive performance trained on iTunes-Amazon and test on Beer with prefix is: f1 0.2828282828282828, acc 0.21978021978021978
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with prefix is: f1 1.0, acc 1.0
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with prefix is: f1 0.42149929278642156, acc 0.8003904343582235
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with prefix is: f1 0.39958395513951067, acc 0.8975141735717401
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with prefix is: f1 0.6818181818181818, acc 0.8358269308532147
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with prefix is: f1 0.7130591956619973, acc 0.8894113549285964
The preditive performance trained on iTunes-Amazon and test on Hospital with prefix is: f1 0.008724400294792349, acc 0.5456990819250336
The preditive performance trained on iTunes-Amazon and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with prefix is: f1 0.40601503759398494, acc 0.27522935779816515
The preditive performance trained on Beer and test on Beer with prefix is: f1 0.8666666666666666, acc 0.9560439560439561
The preditive performance trained on Beer and test on Fodors-Zagats with prefix is: f1 0.2085308056872038, acc 0.1164021164021164
The preditive performance trained on Beer and test on Walmart-Amazon with prefix is: f1 0.2724409448818898, acc 0.5490483162518301
The preditive performance trained on Beer and test on Amazon-Google with prefix is: f1 0.19528907922912206, acc 0.18054949847361534
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with prefix is: f1 0.31965442764578833, acc 0.2357460574201375
The preditive performance trained on Beer and test on DBLP-GoogleScholar with prefix is: f1 0.32619993885661874, acc 0.23232323232323232
The preditive performance trained on Beer and test on Hospital with prefix is: f1 0.05227790432801823, acc 0.026840535641190575
The preditive performance trained on Beer and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with prefix is: f1 0.5454545454545455, acc 0.6330275229357798
The preditive performance trained on Fodors-Zagats and test on Beer with prefix is: f1 0.2828282828282828, acc 0.21978021978021978
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with prefix is: f1 1.0, acc 1.0
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with prefix is: f1 0.2271857051691129, acc 0.40897999023914106
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with prefix is: f1 0.13099979040033535, acc 0.8033144352376799
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with prefix is: f1 0.38141592920353984, acc 0.43469470279013345
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with prefix is: f1 0.253280825792749, acc 0.5191570881226054
The preditive performance trained on Fodors-Zagats and test on Hospital with prefix is: f1 0.02798247432492513, acc 0.2257177942810362
The preditive performance trained on Fodors-Zagats and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Walmart-Amazon and test on Beer with prefix is: f1 0.5957446808510638, acc 0.7912087912087912
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with prefix is: f1 0.37037037037037035, acc 0.91005291005291
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with prefix is: f1 0.8208955223880596, acc 0.9648609077598829
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with prefix is: f1 0.2928818425001631, acc 0.8992586131705189
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with prefix is: f1 0.7418478260869565, acc 0.9231702385766276
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with prefix is: f1 0.34228702993092863, acc 0.8507488679902473
The preditive performance trained on Walmart-Amazon and test on Hospital with prefix is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Walmart-Amazon and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with prefix is: f1 0.8620689655172414, acc 0.926605504587156
The preditive performance trained on Amazon-Google and test on Beer with prefix is: f1 0.7777777777777778, acc 0.9120879120879121
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with prefix is: f1 0.7058823529411764, acc 0.9470899470899471
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with prefix is: f1 0.5995717344753748, acc 0.9087359687652513
The preditive performance trained on Amazon-Google and test on Amazon-Google with prefix is: f1 0.72265625, acc 0.9380723942433493
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with prefix is: f1 0.9012875536480687, acc 0.9627982207844723
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with prefix is: f1 0.8329250367466928, acc 0.9406130268199234
The preditive performance trained on Amazon-Google and test on Hospital with prefix is: f1 0.0017429193899782137, acc 0.9712882287585521
The preditive performance trained on Amazon-Google and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with prefix is: f1 0.4426229508196721, acc 0.3761467889908257
The preditive performance trained on DBLP-ACM and test on Beer with prefix is: f1 0.2692307692307693, acc 0.16483516483516483
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with prefix is: f1 0.4489795918367347, acc 0.7142857142857143
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with prefix is: f1 0.22943387411874627, acc 0.572962420693021
The preditive performance trained on DBLP-ACM and test on Amazon-Google with prefix is: f1 0.3589966168091168, acc 0.8412559965111208
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with prefix is: f1 0.9615806805708014, acc 0.985847149211484
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with prefix is: f1 0.8342189160467588, acc 0.9456635318704284
The preditive performance trained on DBLP-ACM and test on Hospital with prefix is: f1 0.011956001912960307, acc 0.6803110929185427
The preditive performance trained on DBLP-ACM and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with prefix is: f1 0.6923076923076924, acc 0.7798165137614679
The preditive performance trained on DBLP-GoogleScholar and test on Beer with prefix is: f1 0.49122807017543857, acc 0.6813186813186813
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with prefix is: f1 0.9, acc 0.9788359788359788
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with prefix is: f1 0.4740018287107589, acc 0.8867740361151781
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with prefix is: f1 0.4939467312348668, acc 0.9088530309638029
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with prefix is: f1 0.9315068493150684, acc 0.9737161342498989
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with prefix is: f1 0.9418874941887495, acc 0.9782305816788576
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with prefix is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-GoogleScholar and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.7522935779816514
The preditive performance trained on Hospital and test on Beer with prefix is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Hospital and test on Fodors-Zagats with prefix is: f1 0.0, acc 0.8835978835978836
The preditive performance trained on Hospital and test on Walmart-Amazon with prefix is: f1 0.007314843035659859, acc 0.8867740361151781
The preditive performance trained on Hospital and test on Amazon-Google with prefix is: f1 0.016126431220770846, acc 0.8835586567815089
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with prefix is: f1 0.002384737678855326, acc 0.8160129397492923
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with prefix is: f1 0.0028320589068252617, acc 0.8056426332288401
The preditive performance trained on Hospital and test on Hospital with prefix is: f1 0.952054794520548, acc 0.9975440032746623
The preditive performance trained on Hospital and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Beer with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with prefix is: f1 0.0, acc 0.0004880429477794046
The preditive performance trained on Buy and test on Amazon-Google with prefix is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on DBLP-GoogleScholar with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Hospital with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Buy with prefix is: f1 0.0, acc 0.9230769230769231
The preditive performance trained on Buy and test on Restaurant with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on iTunes-Amazon with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Amazon-Google with prefix is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Buy with prefix is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Restaurant with prefix is: f1 0.0, acc 0.7325581395348837
The preditive performance trained on iTunes-Amazon and test on iTunes-Amazon with prompt is: f1 0.7812500000000001, acc 0.8715596330275229
The preditive performance trained on iTunes-Amazon and test on Beer with prompt is: f1 0.3146067415730337, acc 0.32967032967032966
The preditive performance trained on iTunes-Amazon and test on Fodors-Zagats with prompt is: f1 0.21256038647342995, acc 0.13756613756613756
The preditive performance trained on iTunes-Amazon and test on Walmart-Amazon with prompt is: f1 0.17696629213483148, acc 0.14202049780380674
The preditive performance trained on iTunes-Amazon and test on Amazon-Google with prompt is: f1 0.2235469448584203, acc 0.3183602267771478
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on iTunes-Amazon and test on DBLP-ACM with prompt is: f1 0.6082115518441197, acc 0.7723412858875859
The preditive performance trained on iTunes-Amazon and test on DBLP-GoogleScholar with prompt is: f1 0.4765977666904253, acc 0.6163357715081853
The preditive performance trained on iTunes-Amazon and test on Hospital with prompt is: f1 0.0, acc 0.6730015788550378
The preditive performance trained on iTunes-Amazon and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on iTunes-Amazon and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on iTunes-Amazon with prompt is: f1 0.631578947368421, acc 0.7431192660550459
The preditive performance trained on Beer and test on Beer with prompt is: f1 0.7586206896551724, acc 0.9230769230769231
The preditive performance trained on Beer and test on Fodors-Zagats with prompt is: f1 0.2085308056872038, acc 0.1164021164021164
The preditive performance trained on Beer and test on Walmart-Amazon with prompt is: f1 0.14790453179649696, acc 0.3103953147877013
The preditive performance trained on Beer and test on Amazon-Google with prompt is: f1 0.18586179507545672, acc 0.1059747056258177
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Beer and test on DBLP-ACM with prompt is: f1 0.4024219841639497, acc 0.48119692680954307
The preditive performance trained on Beer and test on DBLP-GoogleScholar with prompt is: f1 0.3483127572016461, acc 0.310518982932776
The preditive performance trained on Beer and test on Hospital with prompt is: f1 0.0, acc 0.9183088708262674
The preditive performance trained on Beer and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Beer and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on iTunes-Amazon with prompt is: f1 0.7536231884057971, acc 0.8440366972477065
The preditive performance trained on Fodors-Zagats and test on Beer with prompt is: f1 0.5, acc 0.8901098901098901
The preditive performance trained on Fodors-Zagats and test on Fodors-Zagats with prompt is: f1 0.9767441860465117, acc 0.9947089947089947
The preditive performance trained on Fodors-Zagats and test on Walmart-Amazon with prompt is: f1 0.2026482440990213, acc 0.9004392386530015
The preditive performance trained on Fodors-Zagats and test on Amazon-Google with prompt is: f1 0.21192377749754798, acc 0.8927169646750981
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Fodors-Zagats and test on DBLP-ACM with prompt is: f1 0.5779816513761467, acc 0.8883946623534169
The preditive performance trained on Fodors-Zagats and test on DBLP-GoogleScholar with prompt is: f1 0.3143080531665363, acc 0.8472657610588645
The preditive performance trained on Fodors-Zagats and test on Hospital with prompt is: f1 0.00010617199013025179, acc 0.9137477340506404
The preditive performance trained on Fodors-Zagats and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Fodors-Zagats and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on iTunes-Amazon with prompt is: f1 0.9152542372881356, acc 0.9541284403669725
The preditive performance trained on Walmart-Amazon and test on Beer with prompt is: f1 0.8750000000000001, acc 0.9560439560439561
The preditive performance trained on Walmart-Amazon and test on Fodors-Zagats with prompt is: f1 0.9767441860465117, acc 0.9947089947089947
The preditive performance trained on Walmart-Amazon and test on Walmart-Amazon with prompt is: f1 0.8616187989556136, acc 0.9741337237676916
The preditive performance trained on Walmart-Amazon and test on Amazon-Google with prompt is: f1 0.6185185185185185, acc 0.910161360662887
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Walmart-Amazon and test on DBLP-ACM with prompt is: f1 0.8435114503816794, acc 0.933683784876668
The preditive performance trained on Walmart-Amazon and test on DBLP-GoogleScholar with prompt is: f1 0.8134453781512606, acc 0.922675026123302
The preditive performance trained on Walmart-Amazon and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Walmart-Amazon and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Walmart-Amazon and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on iTunes-Amazon with prompt is: f1 0.6428571428571429, acc 0.7247706422018348
The preditive performance trained on Amazon-Google and test on Beer with prompt is: f1 0.6511627906976745, acc 0.8351648351648352
The preditive performance trained on Amazon-Google and test on Fodors-Zagats with prompt is: f1 0.9361702127659575, acc 0.9841269841269841
The preditive performance trained on Amazon-Google and test on Walmart-Amazon with prompt is: f1 0.44355909694555107, acc 0.7955100048804294
The preditive performance trained on Amazon-Google and test on Amazon-Google with prompt is: f1 0.7643564356435643, acc 0.948102921936328
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Amazon-Google and test on DBLP-ACM with prompt is: f1 0.7670995670995671, acc 0.8912252325111201
The preditive performance trained on Amazon-Google and test on DBLP-GoogleScholar with prompt is: f1 0.793733681462141, acc 0.9036920933472657
The preditive performance trained on Amazon-Google and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on Amazon-Google and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Amazon-Google and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on iTunes-Amazon with prompt is: f1 0.6341463414634146, acc 0.8623853211009175
The preditive performance trained on DBLP-ACM and test on Beer with prompt is: f1 0.8333333333333333, acc 0.9560439560439561
The preditive performance trained on DBLP-ACM and test on Fodors-Zagats with prompt is: f1 1.0, acc 1.0
The preditive performance trained on DBLP-ACM and test on Walmart-Amazon with prompt is: f1 0.3832124352331606, acc 0.8921425085407516
The preditive performance trained on DBLP-ACM and test on Amazon-Google with prompt is: f1 0.5066666666666666, acc 0.9193196685564762
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-ACM and test on DBLP-ACM with prompt is: f1 0.9832402234636871, acc 0.9939344925192074
The preditive performance trained on DBLP-ACM and test on DBLP-GoogleScholar with prompt is: f1 0.6045016077170418, acc 0.8928944618599791
The preditive performance trained on DBLP-ACM and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-ACM and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-ACM and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on iTunes-Amazon with prompt is: f1 0.7441860465116279, acc 0.8990825688073395
The preditive performance trained on DBLP-GoogleScholar and test on Beer with prompt is: f1 0.13333333333333333, acc 0.8571428571428571
The preditive performance trained on DBLP-GoogleScholar and test on Fodors-Zagats with prompt is: f1 0.7777777777777778, acc 0.9576719576719577
The preditive performance trained on DBLP-GoogleScholar and test on Walmart-Amazon with prompt is: f1 0.4551724137931034, acc 0.9228892142508541
The preditive performance trained on DBLP-GoogleScholar and test on Amazon-Google with prompt is: f1 0.4074074074074074, acc 0.9162668992586132
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-ACM with prompt is: f1 0.9625550660792952, acc 0.9862515163768703
The preditive performance trained on DBLP-GoogleScholar and test on DBLP-GoogleScholar with prompt is: f1 0.9592592592592593, acc 0.9846743295019157
The preditive performance trained on DBLP-GoogleScholar and test on Hospital with prompt is: f1 0.0, acc 0.9731594643588094
The preditive performance trained on DBLP-GoogleScholar and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on DBLP-GoogleScholar and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on iTunes-Amazon with prompt is: f1 0.1111111111111111, acc 0.7522935779816514
The preditive performance trained on Hospital and test on Beer with prompt is: f1 0.0, acc 0.8461538461538461
The preditive performance trained on Hospital and test on Fodors-Zagats with prompt is: f1 0.0, acc 0.8835978835978836
The preditive performance trained on Hospital and test on Walmart-Amazon with prompt is: f1 0.0, acc 0.9053196681307956
The preditive performance trained on Hospital and test on Amazon-Google with prompt is: f1 0.0, acc 0.8979502834714348
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Hospital and test on DBLP-ACM with prompt is: f1 0.03633633633633633, acc 0.8232915487262434
The preditive performance trained on Hospital and test on DBLP-GoogleScholar with prompt is: f1 0.05997923156801662, acc 0.8190525949146639
The preditive performance trained on Hospital and test on Hospital with prompt is: f1 0.9161747343565526, acc 0.9958481960119291
The preditive performance trained on Hospital and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Hospital and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on iTunes-Amazon with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Beer with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Fodors-Zagats with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Walmart-Amazon with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Amazon-Google with prompt is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Buy and test on DBLP-ACM with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on DBLP-GoogleScholar with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Hospital with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Buy and test on Buy with prompt is: f1 0.0, acc 0.8307692307692308
The preditive performance trained on Buy and test on Restaurant with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on iTunes-Amazon with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Beer with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Fodors-Zagats with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Walmart-Amazon with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Amazon-Google with prompt is: f1 0.0, acc 0.0
Token indices sequence length is longer than the specified maximum sequence length for this model (397 > 300). Running this sequence through the model will result in indexing errors
The preditive performance trained on Restaurant and test on DBLP-ACM with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on DBLP-GoogleScholar with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Hospital with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Buy with prompt is: f1 0.0, acc 0.0
The preditive performance trained on Restaurant and test on Restaurant with prompt is: f1 0.0, acc 0.37209302325581395
